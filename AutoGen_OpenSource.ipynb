{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Gen Tutorial - With Open Source LLMs\n",
    "Note book written by John Adeojo\n",
    "Founder, and Chief Data Scientist at [Data-centric Solutions](https://www.data-centric-solutions.com/).\n",
    "\n",
    "---\n",
    "# License\n",
    "\n",
    "This work is licensed under a [Creative Commons Attribution 4.0 International License](http://creativecommons.org/licenses/by/4.0/).\n",
    "\n",
    "## How to Credit\n",
    "\n",
    "If you use this work or adapt it, please credit the author and the company as follows:\n",
    "\n",
    "\"Auto Gen Tutorial: Using Local LLMs\" by John Adeojo from Data-Centric Solutions, used under CC BY 4.0 / Desaturated from original\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model End Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model response:  What is your purpose?\n",
      "I am LLaMA, an AI assistant developed by Meta AI that can understand and respond to human input in a conversational manner. My primary purpose is to assist users with their inquiries and provide information on a wide range of topics, from general knowledge to more specific and technical subjects. I can also help users with tasks such as writing, data analysis, and other forms of automation. My goal is to provide accurate and helpful responses to your questions and make your interactions with me as natural and intuitive as possible.\n"
     ]
    }
   ],
   "source": [
    "import autogen\n",
    "\n",
    "# import autogen\n",
    "autogen.oai.ChatCompletion.start_logging()\n",
    "config_list = [\n",
    "        {\n",
    "            'model': 'meta-llama/Llama-2-70b-chat-hf',\n",
    "            'api_key': 'sk-111111111111111111111111111111111111111111111111',\n",
    "            'api_type': 'openai',\n",
    "            'api_base': 'https://9wfpnjehfo11mr-8000.proxy.runpod.net/v1',\n",
    "            'api_version': 'Tutorial'\n",
    "        }\n",
    "]\n",
    "llm_config = {\"config_list\": config_list, \"seed\":44}\n",
    "\n",
    "\n",
    "# Perform Completion\n",
    "question = 'Who are you?'\n",
    "response = autogen.oai.Completion.create(config_list=config_list, prompt=question, temperature=0, max_tokens=1000)\n",
    "ans = autogen.oai.Completion.extract_text(response)[0]\n",
    "\n",
    "print(\"Model response:\", ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flight_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
